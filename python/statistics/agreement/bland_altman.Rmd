---
title: '<font size="5">Statistics in Python:</font><br>Bland-Altman Analysis'
output:
    html_document:
        theme: paper
        highlight: textmate
        number_sections: true
        toc: true
        includes:
            before_body: ../../../google_analytics.html
---

<font size="3">

[⇦ Back](../../../python.html)

**Bland-Altman analysis** is used to assess the agreement between two methods of measuring something, usually clinical information. It was discussed in Bland & Altman's 1986 paper<sup>[1]</sup> and see also the [Wikipedia page](https://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot).

Calculating agreement is useful when discussing:

- Test-retest experiments
- Repeatability and reproducibility
- Reliability
- Intra- and inter-operator agreement
- Intra- and inter-test agreement

> [1] Bland JM, Altman DG. Statistical methods for assessing agreement between two methods of clinical measurement. Lancet. 1986 Feb;327(8476):307–10. DOI: [10.1016/S0140-6736(86)90837-8](https://linkinghub.elsevier.com/retrieve/pii/S0140673686908378). PMID: [2868172](https://pubmed.ncbi.nlm.nih.gov/2868172/).

Where to Start: Bland & Altman's Difference Plot
================================================
The example shown in Bland & Altman's paper uses data created especially for the paper. Bland measured the maximum speed of expiration (peak expiratory flow rate or PEFR) of 17 people, mainly his family and friends, using two different devices: a large and a mini Wright peak flow meter. This data is shown below:

```{python}
import pandas as pd

df = pd.DataFrame({
    'Wright Mini': [
        512, 430, 520, 428, 500, 600, 364, 380, 658,
        445, 432, 626, 260, 477, 259, 350, 451
    ],
    'Wright Large': [
        494, 395, 516, 434, 476, 557, 413, 442, 650,
        433, 417, 656, 267, 478, 178, 423, 427
    ]
})
```

Visualise the Data
==================
Here are the measurements taken by the two different devices plotted against one another (this re-produces Figure 1 of Bland & Altman (1986)):

```{python, eval = FALSE}
import matplotlib.pyplot as plt

# Options
x = 5  # Want figures to be A5
plt.rc('figure', figsize=[46.82 * .5**(.5 * x), 33.11 * .5**(.5 * x)])
plt.rc('text', usetex=True)
plt.rc('font', family='serif')
plt.rc('text.latex', preamble=r'\usepackage{textgreek}')

#
# Plot
#
ax = plt.axes()
ax.set(
    title='Peak Expiratory Flow Rate',
    xlabel='Large Meter (L/min)', ylabel='Mini Meter (L/min)'
)
# Scatter plot
ax.scatter(
    df['Wright Large'], df['Wright Mini'],
    c='k', s=20, alpha=0.6, marker='o'
)
# Get axis limits
left, right = plt.xlim()
# Set axis limits
ax.set_xlim(0, right)
ax.set_ylim(0, right)
# Reference line
ax.plot([0, right], [0, right], c='grey', ls='--', label='Line of Equality')
# Set aspect ratio
ax.set_aspect('equal')
# Legend
ax.legend(frameon=False)
# Show plot
plt.show()
```

```{python, echo = FALSE, results = 'hide'}
import matplotlib.pyplot as plt

# Options
x = 5  # Want figures to be A5
plt.rc('figure', figsize=[46.82 * .5**(.5 * x), 33.11 * .5**(.5 * x)])
plt.rc('text', usetex=True)
plt.rc('font', family='serif')
plt.rc('text.latex', preamble=r'\usepackage{textgreek}')

#
# Plot
#
ax = plt.axes()
ax.set(
    title='Peak Expiratory Flow Rate',
    xlabel='Large Meter (L/min)', ylabel='Mini Meter (L/min)'
)
# Scatter plot
ax.scatter(
    df['Wright Large'], df['Wright Mini'],
    c='k', s=20, alpha=0.6, marker='o'
)
# Get axis limits
left, right = plt.xlim()
# Set axis limits
ax.set_xlim(0, right)
ax.set_ylim(0, right)
# Reference line
ax.plot([0, right], [0, right], c='grey', ls='--', label='Line of Equality')
# Set aspect ratio
ax.set_aspect('equal')
# Legend
ax.legend(frameon=False)
# Show plot
plt.show()
```

Time for Regression Analysis?
=============================
As Bland and Altman say in their paper, at this point it's usual to [calculate the correlation coefficient](correlation_coefficients.html) (*r*) between the two methods. Doing so will give *r* = 0.94 (p < 0.001). They continue: "The null hypothesis here is that the measurements by the two methods are not linearly related. The probability is very small and we can safely conclude that PEFR measurements by the mini and large meters are **related**. However, this high correlation does *not* mean that the two methods **agree**", to paraphrase:

- *r* measures how *correlated* two variables are, not the extent to which they *agree*. Perfect agreement implies that all the points lie along the line of equality, while a large *r* value merely implies that they all lie on a straight line (which could be *any* straight line)
- Correlation depends on the range over which you test. If we only look at the data below 500 L/min or only the data above 500 L/min we get smaller values of *r* (0.88 and 0.90 respectively) than when we look at all the data together (*r* = 0.94). However, it would be absurd to argue that agreement is worse below 500 L/min *and* worse above 500 L/min than it is for everybody.
- The test of significance may show that the two methods are related, but it would be amazing if two methods designed to measure the same quantity were not related! The test of significance is irrelevant to the question of agreement.
- The *r* statistic is difficult to interpret: is an *r* value of 0.992 much worse than one of 0.996? How much worse?

All the above leads us towards looking for a new method of measuring agreement:

Bland-Altman Analysis
=====================
In essence, if we are interested in knowing to what extent two measurement methods differ we should calculate the average difference between the values they produce when measuring the same participant. If this is small it means that it is effectively irrelevant which method you use; both will yield a similar result. The two methods or devices can thus be used interchangeably, or one can be used instead of the other if it is preferable for whatever reason. To check that this measurement difference is not related to the actual value that is being measured, it is useful to plot it against the mean value of the two values (ideally you would plot it against the true value, but as this is unknown the mean value that was measured is your best guess).

First calculate the means and differences. This is the data that will be plotted:

```{python}
means = df.mean(axis=1)
diffs = df.diff(axis=1).iloc[:, -1]
```

Then find the average difference and the standard deviation of the differences. These are good indicators of whether or not a method is biased and how consistent this bias is, respectively:

```{python}
import numpy as np

# Average difference (aka the bias)
bias = np.mean(diffs)
# Sample standard deviation
sd = np.std(diffs, ddof=1)
```

If we assume that the data is Normally distributed it means that 95% of the points lie within two standard deviations of the mean (use 1.96 standard deviations if you want to be more accurate). The endpoints of this 95% range are known as the "limits of agreement" (LOA): 

```{python}
upper_loa = bias + 2 * sd
lower_loa = bias - 2 * sd
```

Now we can plot this data (this plot re-produces Figure 2 of Bland & Altman (1986)):

```{python, eval = FALSE}
ax = plt.axes()
ax.set(
    title='Bland-Altman Plot for Two Methods of Measuring PEFR',
    xlabel='Mean (L/min)', ylabel='Difference (L/min)'
)
# Scatter plot
ax.scatter(means, diffs, c='k', s=20, alpha=0.6, marker='o')
# Plot the zero line
ax.axhline(y=0, c='k', lw=0.5)
# Plot the bias and the limits of agreement
ax.axhline(y=upper_loa, c='grey', ls='--')
ax.axhline(y=bias, c='grey', ls='--')
ax.axhline(y=lower_loa, c='grey', ls='--')
# Get axis limits
left, right = plt.xlim()
bottom, top = plt.ylim()
# Set y-axis limits
max_y = max(abs(bottom), abs(top))
ax.set_ylim(-max_y * 1.1, max_y * 1.1)
# Set x-axis limits
domain = right - left
ax.set_xlim(left, left + domain * 1.1)
# Add the annotations
ax.annotate('+2×SD', (right, upper_loa), (0, 7), textcoords='offset pixels')
ax.annotate(f'{upper_loa:+4.2f}', (right, upper_loa), (0, -25), textcoords='offset pixels')
ax.annotate('Bias', (right, bias), (0, 7), textcoords='offset pixels')
ax.annotate(f'{bias:+4.2f}', (right, bias), (0, -25), textcoords='offset pixels')
ax.annotate('-2×SD', (right, lower_loa), (0, 7), textcoords='offset pixels')
ax.annotate(f'{lower_loa:+4.2f}', (right, lower_loa), (0, -25), textcoords='offset pixels')
# Show plot
plt.show()
```

```{python, echo = FALSE, results = 'hide'}
ax = plt.axes()
ax.set(
    title='Bland-Altman Plot for Two Methods of Measuring PEFR',
    xlabel='Mean (L/min)', ylabel='Difference (L/min)'
)
# Scatter plot
ax.scatter(means, diffs, c='k', s=20, alpha=0.6, marker='o')
# Plot the zero line
ax.axhline(y=0, c='k', lw=0.5)
# Plot the bias and the limits of agreement
ax.axhline(y=upper_loa, c='grey', ls='--')
ax.axhline(y=bias, c='grey', ls='--')
ax.axhline(y=lower_loa, c='grey', ls='--')
# Get axis limits
left, right = plt.xlim()
bottom, top = plt.ylim()
# Set y-axis limits
max_y = max(abs(bottom), abs(top))
ax.set_ylim(-max_y * 1.1, max_y * 1.1)
# Set x-axis limits
domain = right - left
ax.set_xlim(left, left + domain * 1.1)
# Add the annotations
ax.annotate('+2×SD', (right, upper_loa), (0, 7), textcoords='offset pixels')
ax.annotate(f'{upper_loa:+4.2f}', (right, upper_loa), (0, -25), textcoords='offset pixels')
ax.annotate('Bias', (right, bias), (0, 7), textcoords='offset pixels')
ax.annotate(f'{bias:+4.2f}', (right, bias), (0, -25), textcoords='offset pixels')
ax.annotate('-2×SD', (right, lower_loa), (0, 7), textcoords='offset pixels')
ax.annotate(f'{lower_loa:+4.2f}', (right, lower_loa), (0, -25), textcoords='offset pixels')
# Show plot
plt.show()
```

Confidence Intervals
====================
Neither the bias line nor the limits of agreement are known with certainty. The standard error of the bias can be estimate as:

${se}_{bias} = \sqrt{\frac{ {sd}^2}{n}}$

where $sd$ is the sample standard deviation and $n$ is the sample size. Similarly, the standard errors of the limits of agreement are approximately:

${se}_{LOA} = \sqrt{\frac{3{sd}^2}{n}}$

If we use the Student's t distribution we can calculate a "t-statistic" that corresponds to a 95% confidence interval given $n-1$ degrees of freedom. This will then give us the confidence intervals on the bias and LOA lines as follows:

${CI} = y\pm\left(t\times{se}\right)$

where $y$ is the horizontal line in question (bias, upper LOA or lower LOA) and $t$ is the t-statistic. In Python, these calculations look as follows:

```{python}
import scipy.stats as stats

# Sample size
n = df.shape[0]
# Variance
var = sd**2
# Standard error of the bias
se_bias = np.sqrt(var / n)
# Standard error of the limits of agreement
se_loas = np.sqrt(3 * var / n)
# Endpoints of the range that contains 95% of the Student’s t distribution
t_interval = stats.t.interval(alpha=0.95, df=n - 1)
# Confidence intervals
ci_bias = bias + np.array(t_interval) * se_bias
ci_upperloa = upper_loa + np.array(t_interval) * se_loas
ci_lowerloa = lower_loa + np.array(t_interval) * se_loas
```

These can now be added to the plot:

```{python, eval = FALSE}
# Plot the confidence intervals
ax.plot([left] * 2, list(ci_upperloa), c='grey', ls='--', alpha=0.5)
ax.plot([left] * 2, list(ci_bias), c='grey', ls='--', alpha=0.5)
ax.plot([left] * 2, list(ci_lowerloa), c='grey', ls='--', alpha=0.5)
# Plot the confidence intervals' caps
x_range = [left - domain * 0.025, left + domain * 0.025]
ax.plot(x_range, [ci_upperloa[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_upperloa[0]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_bias[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_bias[0]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_lowerloa[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_lowerloa[0]] * 2, c='grey', ls='--', alpha=0.5)
```

```{python, echo = FALSE, results = 'hide'}
ax = plt.axes()
ax.set(
    title='Bland-Altman Plot for Two Methods of Measuring PEFR',
    xlabel='Mean (L/min)', ylabel='Difference (L/min)'
)
# Scatter plot
ax.scatter(means, diffs, c='k', s=20, alpha=0.6, marker='o')
# Plot the zero line
ax.axhline(y=0, c='k', lw=0.5)
# Plot the bias and the limits of agreement
ax.axhline(y=upper_loa, c='grey', ls='--')
ax.axhline(y=bias, c='grey', ls='--')
ax.axhline(y=lower_loa, c='grey', ls='--')
# Get axis limits
left, right = plt.xlim()
bottom, top = plt.ylim()
# Increase the y-axis limits to create space for the confidence intervals
max_y = max(abs(ci_lowerloa[0]), abs(ci_upperloa[1]), abs(bottom), abs(top))
ax.set_ylim(-max_y * 1.1, max_y * 1.1)
# Set x-axis limits
domain = right - left
ax.set_xlim(left - domain * 0.05, left + domain * 1.1)
# Add the annotations
ax.annotate(
    '+2×SD', (right, upper_loa), xytext=(0, 7), textcoords='offset pixels'
)
ax.annotate(
    f'{upper_loa:+4.2f}', (right, upper_loa), xytext=(0, -25),
    textcoords='offset pixels'
)
ax.annotate(
    'Bias', (right, bias), xytext=(0, 7), textcoords='offset pixels'
)
ax.annotate(
    f'{bias:+4.2f}', (right, bias), xytext=(0, -25),
    textcoords='offset pixels'
)
ax.annotate(
    '-2×SD', (right, lower_loa), xytext=(0, 7), textcoords='offset pixels'
)
ax.annotate(
    f'{lower_loa:+4.2f}', (right, lower_loa), xytext=(0, -25),
    textcoords='offset pixels'
)
# Plot the confidence intervals
ax.plot([left] * 2, list(ci_upperloa), c='grey', ls='--', alpha=0.5)
ax.plot([left] * 2, list(ci_bias), c='grey', ls='--', alpha=0.5)
ax.plot([left] * 2, list(ci_lowerloa), c='grey', ls='--', alpha=0.5)
# Plot the confidence intervals' caps
x_range = [left - domain * 0.025, left + domain * 0.025]
ax.plot(x_range, [ci_upperloa[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_upperloa[0]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_bias[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_bias[0]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_lowerloa[1]] * 2, c='grey', ls='--', alpha=0.5)
ax.plot(x_range, [ci_lowerloa[0]] * 2, c='grey', ls='--', alpha=0.5)
# Show plot
plt.show()
```

How Does the Accuracy of the Test Change with Sample Size?
==========================================================
The widths of the 95% confidence intervals depend on two factors: the standard deviation and the sample size. Obviously, when designing an experiment, you can't control what the deviation of you data will be, but you CAN control the number of samples you test. Hence, it's useful to know how this number will affect the confidence you will have in your result.

As mentioned above, the confidence intervals are calculated as:

${CI} = y\pm\left(t\times{se}\right)$

which implies that the half-widths of the confidence intervals are:

$t\times{se}$

which means that the full-widths of the confidence intervals for the bias and LOA lines, respectively, are twice these:

${CI}^{width}_{bias} = 2\times t\times \sqrt{\frac{ {sd}^2}{n}}$

${CI}^{width}_{LOA} = 2\times t\times \sqrt{\frac{3 {sd}^2}{n}}$

so the widths of the confidence intervals *relative to the sample standard deviations* are:

${CI}^{width}_{bias} = 2\times t\times \sqrt{\frac{1}{n}}$

${CI}^{width}_{LOA} = 2\times t\times \sqrt{\frac{3}{n}}$

In Python, these are calculated as:

```{python, eval = FALSE}
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(1 / n)
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
```

and they can be plotted as follows:

```{python, eval = FALSE}
ax = plt.axes()
ax.set(
    title=r'The widths of the confidence intervals (relative to the\\sample standard deviation) decrease if there are more samples',
    xlabel='Sample Size (n)',
    ylabel=r'Width of Confidence Intervals\\(Relative to Sample Standard Deviation)'
)
# Scatter plots
n = np.arange(5, 51)
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
ax.scatter(n, width, c='k', s=20, alpha=0.6, marker='o')
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(1 / n)
ax.scatter(n, width, c='k', s=20, alpha=0.6, marker='o')
# Smooth curves
n = np.arange(5, 50, 0.1)
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
ax.plot(n, width, label=r'LOAs $\left(2\times t\times\sqrt{\frac{3}{n}}\right)$')
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(1 / n)
ax.plot(n, width, c='tab:blue', alpha=0.2, label=r'Bias $\left(2\times t\times\sqrt{\frac{1}{n}}\right)$')
# Set y-axis limits
bottom, top = plt.ylim()
ax.set_ylim(0, top)
# Set x-axis limits
ax.set_xlim(5, 50)
# Legend
ax.legend(frameon=False)
# Show plot
plt.show()
```

```{python, echo = FALSE, results = 'hide'}
ax = plt.axes()
ax.set(
    title=r'The widths of the confidence intervals (relative to the\\sample standard deviation) decrease if there are more samples',
    xlabel='Sample Size (n)',
    ylabel=r'Width of Confidence Intervals\\(Relative to Sample Standard Deviation)'
)
# Scatter plots
n = np.arange(5, 51)
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
ax.scatter(n, width, c='k', s=20, alpha=0.6, marker='o')
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(1 / n)
ax.scatter(n, width, c='k', s=20, alpha=0.6, marker='o')
# Smooth curves
n = np.arange(5, 50, 0.1)
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
ax.plot(n, width, label=r'LOAs $\left(2\times t\times\sqrt{\frac{3}{n}}\right)$')
width = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(1 / n)
ax.plot(n, width, c='tab:blue', alpha=0.2, label=r'Bias $\left(2\times t\times\sqrt{\frac{1}{n}}\right)$')
# Set y-axis limits
bottom, top = plt.ylim()
ax.set_ylim(0, top)
# Set x-axis limits
ax.set_xlim(5, 50)
# Legend
ax.legend(frameon=False)
# Show plot
plt.show()
```

As an example, if you decrease your sample size from 40 to 30, the widths of the confidence intervals of your limits of agreement will increase by 16.8%:

```{python}
n = 40
width_40 = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
n = 30
width_30 = 2 * stats.t.interval(alpha=0.95, df=n - 1)[1] * np.sqrt(3 / n)
increase = (width_30 - width_40) / width_40 * 100
print(
    f"Your confidence intervals' widths have gone from {width_40:4.2f} standard deviations to " +
    f"{width_30:4.2f} standard deviations, an increase of {increase:4.1f}%"
)
```

A Bland-Altman Function
=======================
When doing multiple Bland-Altman calculations it's often useful to have it as a function. Multiple data sets can then be analysed in quick succession. Here's an example of such a function:

```{python}
def bland_altman_analysis(df):
    """Calculate agreement statistics."""
    tests = list(df)

    # Individual sample calculations
    df['Mean'] = df[tests].mean(axis=1)
    df['Diff'] = df[tests].diff(axis=1)[tests[-1]]
    df['SD'] = df[tests].std(axis=1, ddof=1)
    df['Variance'] = df['SD']**2

    # Whole sample calculations
    summary = pd.DataFrame()
    means = ['Mean of ' + test for test in tests]
    for i, mean in enumerate(means):
        summary.loc[1, mean] = df[tests[i]].mean()
    # Sample size
    summary.loc[1, 'N'] = df.shape[0]
    # Degrees of freedom
    summary.loc[1, 'DoF'] = df.shape[0] - 1
    # Bias (mean difference)
    mean_diff = df['Diff'].mean()
    summary.loc[1, 'Mean Diff (Bias)'] = mean_diff
    # Standard deviation of the differences
    st_dev_diff = df['Diff'].std(ddof=0)
    summary.loc[1, 'SD Diffs'] = st_dev_diff
    summary.loc[1, 'Lower LoA'] = mean_diff - 1.96 * st_dev_diff
    summary.loc[1, 'Upper LoA'] = mean_diff + 1.96 * st_dev_diff
    # Within-subject standard deviation
    s_w = np.sqrt(df['Variance'].mean())
    summary.loc[1, 'Within-Subject SD (Sw)'] = s_w
    # Coefficient of repeatability
    col = 'Repeatability Coefficient (RC)'
    summary.loc[1, col] = np.sqrt(2) * 1.96 * s_w

    # Return
    return df, summary
```

...and here is how it can be used:

O'Brien and Kaiser's Repeated-Measures Data
-------------------------------------------
From the [R Documentation](https://vincentarelbundock.github.io/Rdatasets/doc/carData/OBrienKaiser.html): "These contrived repeated-measures data are taken from O'Brien and Kaiser (1985). The data are from an imaginary study in which 16 female and male subjects, who are divided into three treatments, are measured at a pretest, postest, and a follow-up session; during each session, they are measured at five occasions at intervals of one hour. The design, therefore, has two between-subject and two within-subject factors."

```{python, echo = FALSE}
# Hide SettingWithCopyWarning
pd.options.mode.chained_assignment = None
pd.set_option('display.max_columns', 20)
```

```{python}
from pydataset import data

OBrienKaiser = data('OBrienKaiser')
df = OBrienKaiser[['pre.3', 'pre.4']]
df, summary = bland_altman_analysis(df)
print(summary)
```

Statsmodels
-----------
This example comes from [here](https://www.statsmodels.org/stable/generated/statsmodels.graphics.agreement.mean_diff_plot.html):

```{python}
np.random.seed(9999)
m1 = np.random.random(20)
m2 = np.random.random(20)
df = pd.DataFrame({
    'pre.1': m2,
    'pre.2': m1
})
df, summary = bland_altman_analysis(df)
print(summary)
```

Bland-Altman (1986)
-------------------
These examples come from the same Bland & Altman (1986) paper<sup>[1]</sup>:

```{python}
# Raw data
wright_large = pd.DataFrame({
    'First Measurement': [
        494, 395, 516, 434, 476, 557, 413, 442, 650, 433, 417, 656, 267, 478, 178, 423, 427
    ],
    'Second Measurement': [
        490, 397, 512, 401, 470, 611, 415, 431, 638, 429, 420, 633, 275, 492, 165, 372, 421
    ],
})
# Bland-Altman analysis
df, summary = bland_altman_analysis(wright_large)
print(summary)
```

```{python}
# Raw data
wright_mini = pd.DataFrame({
    'First Measurement': [
        512, 430, 520, 428, 500, 600, 364, 380, 658, 445, 432, 626, 260, 477, 259, 350, 451
    ],
    'Second Measurement': [
        525, 415, 508, 444, 500, 625, 460, 390, 642, 432, 420, 605, 227, 467, 268, 370, 443
    ],
})
# Bland-Altman analysis
df, summary = bland_altman_analysis(wright_mini)
print(summary)
```

Giavarina and Euser Analyses?
=============================
Other authors has expanded upon Bland and Altman's ideas:

**Giavarina analysis** is identical to Bland-Altman analysis except that it accounts for [heteroscedasticity](https://en.wikipedia.org/wiki/Heteroscedasticity). It does this by using percentage differences (relative to the means) on the y-axis instead of raw differences. It was published in Giavarina's 2015 paper<sup>[2]</sup> and a tutorial that replicates elements of that paper is over [here](giavarina.html).

**Euser analysis** also accounts for heteroscedasticity except that it does so via a logarithmic transformation. While this approach was mentioned in Bland & Altman (1986) it was Euser, Dekker & Le Cessie who published a method to transform the data back into the native space and calculate a meaningful coefficient of variation<sup>[3]</sup>. A tutorial is over [here](euser.html).

> [2] Giavarina D. Understanding Bland Altman analysis. Biochemia Medica. 2015;25(2):141-151. DOI: [10.11613/BM.2015.015](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4470095/pdf/bm-25-141.pdf).
> 
> [3] Euser AM, Dekker FW, Le Cessie S. A practical approach to Bland-Altman plots and variation coefficients for log transformed variables. J Clin Epidemiol. 2008;61(10):978–82. DOI: [10.1016/j.jclinepi.2007.11.003](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.564.9186&rep=rep1&type=pdf)

[⇦ Back](../../../python.html)

</font>
